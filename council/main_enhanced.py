"""
Enhanced Council Service with Specialized Agents
QA, Security, Performance, Architecture, and Chairman agents
"""

import os
import json
import re
from typing import Dict, Any, List
from datetime import datetime
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import httpx
from dotenv import load_dotenv

load_dotenv()

app = FastAPI(title="Enhanced Council Service", version="2.0.0")

# Configuration
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"


# Request/Response Models
class CodeReviewRequest(BaseModel):
    code: str
    language: str = "javascript"
    context: str = ""
    quality_gates: List[str] = ["qa", "security", "performance"]


class SecurityScanRequest(BaseModel):
    code: str
    language: str = "javascript"


class PerformanceScanRequest(BaseModel):
    code: str
    language: str = "javascript"


class TestGenerationRequest(BaseModel):
    code: str
    language: str = "javascript"
    test_framework: str = "jest"


class FixRequest(BaseModel):
    code: str
    language: str
    findings: List[Dict[str, Any]]


# LLM Client
class LLMClient:
    """Client for OpenRouter API"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = OPENROUTER_BASE_URL
    
    async def chat(self, messages: List[Dict], model: str = "anthropic/claude-3.5-sonnet"):
        """Send chat request to OpenRouter"""
        async with httpx.AsyncClient(timeout=120.0) as client:
            try:
                response = await client.post(
                    f"{self.base_url}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": model,
                        "messages": messages
                    }
                )
                response.raise_for_status()
                data = response.json()
                return data["choices"][0]["message"]["content"]
            except Exception as e:
                print(f"LLM API error: {e}")
                raise HTTPException(status_code=500, detail=f"LLM API error: {str(e)}")


llm_client = LLMClient(OPENROUTER_API_KEY) if OPENROUTER_API_KEY else None


# QA Agent
class QAAgent:
    """Quality Assurance Agent - Test generation and coverage analysis"""
    
    async def analyze(self, code: str, language: str, context: str) -> Dict[str, Any]:
        """Analyze code for testing quality"""
        
        prompt = f"""You are a QA expert. Analyze this {language} code and provide:

1. Test coverage assessment
2. Missing test cases
3. Edge cases not covered
4. Error handling gaps
5. Test recommendations

Code:
```{language}
{code}
```

Context: {context}

Respond in JSON format:
{{
  "findings": [
    {{
      "severity": "high|medium|low",
      "type": "missing_tests|edge_case|error_handling",
      "description": "...",
      "location": "line X or function name",
      "fix": "..."
    }}
  ],
  "coverage": {{
    "estimated_lines": 0-100,
    "estimated_branches": 0-100,
    "estimated_functions": 0-100
  }},
  "score": 0-100
}}"""

        messages = [{"role": "user", "content": prompt}]
        response = await llm_client.chat(messages)
        
        # Parse JSON from response
        try:
            # Extract JSON from markdown code blocks if present
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response, re.DOTALL)
            if json_match:
                response = json_match.group(1)
            
            result = json.loads(response)
            return {
                "name": "QA Agent",
                "status": "completed",
                "findings": result.get("findings", []),
                "coverage": result.get("coverage", {}),
                "score": result.get("score", 50)
            }
        except json.JSONDecodeError:
            # Fallback if JSON parsing fails
            return {
                "name": "QA Agent",
                "status": "completed",
                "findings": [{
                    "severity": "medium",
                    "type": "analysis_error",
                    "description": "Could not parse QA analysis",
                    "location": "N/A",
                    "fix": "Manual review recommended"
                }],
                "coverage": {"estimated_lines": 0, "estimated_branches": 0, "estimated_functions": 0},
                "score": 50
            }
    
    async def generate_tests(self, code: str, language: str, test_framework: str) -> Dict[str, Any]:
        """Generate test cases for code"""
        
        prompt = f"""Generate comprehensive test cases for this {language} code using {test_framework}.

Code:
```{language}
{code}
```

Generate tests that cover:
1. Normal cases
2. Edge cases
3. Error cases
4. Boundary conditions

Respond in JSON format:
{{
  "test_code": "...",
  "test_count": 5,
  "test_cases": [
    {{
      "name": "test name",
      "type": "unit|integration|edge",
      "description": "..."
    }}
  ],
  "coverage": {{
    "functions": 100,
    "lines": 90,
    "branches": 85
  }}
}}"""

        messages = [{"role": "user", "content": prompt}]
        response = await llm_client.chat(messages)
        
        try:
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response, re.DOTALL)
            if json_match:
                response = json_match.group(1)
            
            result = json.loads(response)
            return result
        except json.JSONDecodeError:
            # Extract test code from code blocks
            code_match = re.search(r'```(?:\w+)?\s*(.*?)\s*```', response, re.DOTALL)
            test_code = code_match.group(1) if code_match else response
            
            return {
                "test_code": test_code,
                "test_count": 1,
                "test_cases": [{"name": "generated_test", "type": "unit", "description": "Generated test"}],
                "coverage": {"functions": 80, "lines": 70, "branches": 60}
            }


# Security Agent
class SecurityAgent:
    """Security Agent - Vulnerability detection and pen-testing"""
    
    async def analyze(self, code: str, language: str, context: str) -> Dict[str, Any]:
        """Analyze code for security vulnerabilities"""
        
        prompt = f"""You are a security expert and penetration tester. Analyze this {language} code for vulnerabilities:

1. OWASP Top 10 vulnerabilities
2. SQL injection risks
3. XSS vulnerabilities
4. Authentication/authorization issues
5. Prompt injection (for AI features)
6. Secret exposure
7. Input validation issues

Code:
```{language}
{code}
```

Context: {context}

For each vulnerability found, provide:
- Severity (critical/high/medium/low)
- Type of vulnerability
- Description
- Location in code
- Example exploit
- Fix recommendation

Respond in JSON format:
{{
  "findings": [
    {{
      "severity": "critical|high|medium|low",
      "type": "sql_injection|xss|auth_bypass|prompt_injection|secret_exposure|...",
      "description": "...",
      "location": "line X",
      "exploit": "example attack",
      "fix": "..."
    }}
  ],
  "score": 0-100
}}"""

        messages = [{"role": "user", "content": prompt}]
        response = await llm_client.chat(messages)
        
        try:
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response, re.DOTALL)
            if json_match:
                response = json_match.group(1)
            
            result = json.loads(response)
            return {
                "name": "Security Agent",
                "status": "completed",
                "findings": result.get("findings", []),
                "score": result.get("score", 50)
            }
        except json.JSONDecodeError:
            return {
                "name": "Security Agent",
                "status": "completed",
                "findings": [{
                    "severity": "medium",
                    "type": "analysis_error",
                    "description": "Could not parse security analysis",
                    "location": "N/A",
                    "exploit": "N/A",
                    "fix": "Manual security review recommended"
                }],
                "score": 50
            }


# Performance Agent
class PerformanceAgent:
    """Performance Agent - Performance analysis and optimization"""
    
    async def analyze(self, code: str, language: str, context: str) -> Dict[str, Any]:
        """Analyze code for performance issues"""
        
        prompt = f"""You are a performance optimization expert. Analyze this {language} code for:

1. N+1 query problems
2. Inefficient algorithms (O(nÂ²) or worse)
3. Memory leaks
4. Unnecessary computations
5. Blocking operations
6. Missing caching opportunities

Code:
```{language}
{code}
```

Context: {context}

Respond in JSON format:
{{
  "findings": [
    {{
      "severity": "high|medium|low",
      "type": "n_plus_one|inefficient_algorithm|memory_leak|blocking_operation|...",
      "description": "...",
      "location": "line X",
      "impact": "performance impact description",
      "fix": "..."
    }}
  ],
  "benchmarks": {{
    "estimated_complexity": "O(n)",
    "estimated_memory": "high|medium|low"
  }},
  "score": 0-100
}}"""

        messages = [{"role": "user", "content": prompt}]
        response = await llm_client.chat(messages)
        
        try:
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response, re.DOTALL)
            if json_match:
                response = json_match.group(1)
            
            result = json.loads(response)
            return {
                "name": "Performance Agent",
                "status": "completed",
                "findings": result.get("findings", []),
                "benchmarks": result.get("benchmarks", {}),
                "score": result.get("score", 50)
            }
        except json.JSONDecodeError:
            return {
                "name": "Performance Agent",
                "status": "completed",
                "findings": [],
                "benchmarks": {},
                "score": 70
            }


# Architecture Agent
class ArchitectureAgent:
    """Architecture Agent - Design patterns and best practices"""
    
    async def analyze(self, code: str, language: str, context: str) -> Dict[str, Any]:
        """Analyze code architecture and design"""
        
        prompt = f"""You are a software architecture expert. Analyze this {language} code for:

1. Design pattern usage
2. SOLID principles adherence
3. Code structure and organization
4. Coupling and cohesion
5. Maintainability issues
6. Code smells

Code:
```{language}
{code}
```

Context: {context}

Respond in JSON format:
{{
  "findings": [
    {{
      "severity": "high|medium|low",
      "type": "tight_coupling|low_cohesion|code_smell|...",
      "description": "...",
      "location": "...",
      "fix": "..."
    }}
  ],
  "metrics": {{
    "maintainability_index": 0-100,
    "coupling": "high|medium|low",
    "cohesion": "high|medium|low"
  }},
  "score": 0-100
}}"""

        messages = [{"role": "user", "content": prompt}]
        response = await llm_client.chat(messages)
        
        try:
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response, re.DOTALL)
            if json_match:
                response = json_match.group(1)
            
            result = json.loads(response)
            return {
                "name": "Architecture Agent",
                "status": "completed",
                "findings": result.get("findings", []),
                "metrics": result.get("metrics", {}),
                "score": result.get("score", 50)
            }
        except json.JSONDecodeError:
            return {
                "name": "Architecture Agent",
                "status": "completed",
                "findings": [],
                "metrics": {},
                "score": 70
            }


# Chairman Agent
class ChairmanAgent:
    """Chairman Agent - Synthesizes findings from all agents"""
    
    def synthesize(self, agents_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Synthesize findings from all agents"""
        
        all_findings = []
        for agent in agents_results:
            for finding in agent.get("findings", []):
                all_findings.append({
                    **finding,
                    "agent": agent["name"]
                })
        
        # Count by severity
        summary = {
            "critical": sum(1 for f in all_findings if f.get("severity") == "critical"),
            "high": sum(1 for f in all_findings if f.get("severity") == "high"),
            "medium": sum(1 for f in all_findings if f.get("severity") == "medium"),
            "low": sum(1 for f in all_findings if f.get("severity") == "low")
        }
        
        # Calculate overall score (weighted average)
        scores = [agent.get("score", 50) for agent in agents_results]
        overall_score = sum(scores) // len(scores) if scores else 50
        
        # Determine quality gate
        quality_gate = "passed" if summary["critical"] == 0 and summary["high"] == 0 and overall_score >= 70 else "failed"
        
        # Priority fixes (critical and high severity)
        priority_fixes = [
            {
                "priority": i + 1,
                "issue": f["description"],
                "severity": f["severity"],
                "agent": f["agent"],
                "fix": f.get("fix", "Manual review required")
            }
            for i, f in enumerate(sorted(
                [f for f in all_findings if f.get("severity") in ["critical", "high"]],
                key=lambda x: 0 if x.get("severity") == "critical" else 1
            )[:10])  # Top 10 priority fixes
        ]
        
        # Generate recommendation
        if quality_gate == "passed":
            recommendation = "Code meets quality standards and is ready for production."
        elif summary["critical"] > 0:
            recommendation = f"CRITICAL: {summary['critical']} critical issue(s) must be fixed before deployment."
        elif summary["high"] > 0:
            recommendation = f"Fix {summary['high']} high-priority issue(s) before deployment."
        else:
            recommendation = "Address medium and low priority issues to improve code quality."
        
        return {
            "overall_score": overall_score,
            "quality_gate": quality_gate,
            "summary": summary,
            "priority_fixes": priority_fixes,
            "agents": agents_results,
            "recommendation": recommendation
        }


# Initialize agents
qa_agent = QAAgent()
security_agent = SecurityAgent()
performance_agent = PerformanceAgent()
architecture_agent = ArchitectureAgent()
chairman_agent = ChairmanAgent()


# API Endpoints

@app.post("/council/review")
async def review_code(request: CodeReviewRequest):
    """Comprehensive code review by all agents"""
    
    if not llm_client:
        raise HTTPException(status_code=500, detail="LLM API not configured")
    
    agents_results = []
    
    # Run requested agents
    if "qa" in request.quality_gates:
        qa_result = await qa_agent.analyze(request.code, request.language, request.context)
        agents_results.append(qa_result)
    
    if "security" in request.quality_gates:
        security_result = await security_agent.analyze(request.code, request.language, request.context)
        agents_results.append(security_result)
    
    if "performance" in request.quality_gates:
        performance_result = await performance_agent.analyze(request.code, request.language, request.context)
        agents_results.append(performance_result)
    
    if "architecture" in request.quality_gates:
        architecture_result = await architecture_agent.analyze(request.code, request.language, request.context)
        agents_results.append(architecture_result)
    
    # Chairman synthesizes
    report = chairman_agent.synthesize(agents_results)
    
    return {
        "agents": agents_results,
        "report": report
    }


@app.post("/council/security")
async def security_scan(request: SecurityScanRequest):
    """Quick security scan"""
    
    if not llm_client:
        raise HTTPException(status_code=500, detail="LLM API not configured")
    
    result = await security_agent.analyze(request.code, request.language, "")
    return result


@app.post("/council/performance")
async def performance_scan(request: PerformanceScanRequest):
    """Quick performance scan"""
    
    if not llm_client:
        raise HTTPException(status_code=500, detail="LLM API not configured")
    
    result = await performance_agent.analyze(request.code, request.language, "")
    return result


@app.post("/council/qa/generate-tests")
async def generate_tests(request: TestGenerationRequest):
    """Generate test cases"""
    
    if not llm_client:
        raise HTTPException(status_code=500, detail="LLM API not configured")
    
    result = await qa_agent.generate_tests(request.code, request.language, request.test_framework)
    return result


@app.post("/council/fix")
async def apply_fixes(request: FixRequest):
    """Apply fixes to code based on findings"""
    
    if not llm_client:
        raise HTTPException(status_code=500, detail="LLM API not configured")
    
    # Generate fixed code using LLM
    findings_text = "\n".join([
        f"- {f['description']} (Fix: {f.get('fix', 'N/A')})"
        for f in request.findings
    ])
    
    prompt = f"""Fix the following issues in this {request.language} code:

{findings_text}

Original code:
```{request.language}
{request.code}
```

Provide the fixed code and explain what changes were made.

Respond in JSON format:
{{
  "fixed_code": "...",
  "changes": [
    {{
      "description": "...",
      "file": "main file",
      "lines": "X-Y"
    }}
  ],
  "fixes_applied": 3,
  "needs_review": false
}}"""

    messages = [{"role": "user", "content": prompt}]
    response = await llm_client.chat(messages)
    
    try:
        json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response, re.DOTALL)
        if json_match:
            response = json_match.group(1)
        
        result = json.loads(response)
        return result
    except json.JSONDecodeError:
        # Extract code from code blocks
        code_match = re.search(r'```(?:\w+)?\s*(.*?)\s*```', response, re.DOTALL)
        fixed_code = code_match.group(1) if code_match else request.code
        
        return {
            "fixed_code": fixed_code,
            "changes": [{"description": "Applied fixes", "file": "main", "lines": "N/A"}],
            "fixes_applied": len(request.findings),
            "needs_review": True
        }


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "enhanced-council",
        "llm_configured": llm_client is not None
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
